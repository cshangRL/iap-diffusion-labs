{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8091b-0bb5-4994-852b-00ab8725ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab2: Flow matching and score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442845a-b870-489a-b4f1-338204f1552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8223e-7c50-4c00-9c36-0deaf6b4bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampleable(ABC):\n",
    "    \"\"\"\n",
    "    Distribution which can be sampled from.\n",
    "    \"\"\"\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def dim(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            - Dimensionality of the distribution\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples.\n",
    "        Returns:\n",
    "            - samples: shape (batch_size, dim)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class Density(ABC):\n",
    "    \"\"\"\n",
    "    Distribution with tractable density.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the log density at x.\n",
    "        Args:\n",
    "            - x: shape (batch_size, dim)\n",
    "        Returns:\n",
    "            - log_density: shape (batch_size, 1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class Gaussian(torch.nn.Module, Sampleable, Density):\n",
    "    def __init__(self, mean: torch.Tensor, cov: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        self.register_buffer(\"cov\", cov)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.mean.shape[0]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MultivariateNormal(self.mean, self.cov, validate_args=False)\n",
    "\n",
    "    def sample(self, num_samples) -> torch.Tensor:\n",
    "        return self.distribution.sample((num_samples,))\n",
    "\n",
    "    def log_density(self, x: torch.Tensor):\n",
    "        return self.distribution.log_prob(x).view(-1,1)\n",
    "\n",
    "    @classmethod\n",
    "    def isotropic(cls, dim: int, std: float) -> \"Gaussian\":\n",
    "        mean = torch.zeros(dim)\n",
    "        cov = torch.eye(dim) * std ** 2\n",
    "        return cls(mean, cov)\n",
    "\n",
    "class GaussianMixture(torch.nn.Module, Sampleable, Density):\n",
    "    def __init__(\n",
    "        self,\n",
    "        means: torch.Tensor,\n",
    "        covs: torch.Tensor,\n",
    "        weights: torch.Tensor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nmodes = means.shape[0]\n",
    "        self.register_buffer(\"means\", means)\n",
    "        self.register_buffer(\"covs\", covs)\n",
    "        self.register_buffer(\"weights\", weights)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.means.shape[1]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MixtureSameFamily(\n",
    "            mixture_distribution=D.Categorical(probs=self.weights, validate_args=False),\n",
    "            component_distribution=D.MultivariateNormal(\n",
    "                loc=self.means,\n",
    "                covariance_matrix=self.covs,\n",
    "                validate_args=False,\n",
    "            ),\n",
    "            validate_args=False,\n",
    "        )\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.distribution.log_prob(x).view(-1, 1)\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        return self.distribution.sample(torch.Size((num_samples,)))\n",
    "\n",
    "    @classmethod\n",
    "    def random_2D(\n",
    "        cls, nmodes: int, std: float, scale: float = 10.0, x_offset: float = 0.0, seed = 0.0\n",
    "    ) -> \"GaussianMixture\":\n",
    "        torch.manual_seed(seed)\n",
    "        means = (torch.rand(nmodes, 2) - 0.5) * scale + x_offset * torch.Tensor([1.0, 0.0])\n",
    "        covs = torch.diag_embed(torch.ones(nmodes, 2)) * std **2\n",
    "        weights = torch.ones(nmodes)\n",
    "        return cls(means, covs, weights)\n",
    "\n",
    "    @classmethod\n",
    "    def symmetric_2D(\n",
    "        cls, nmodes: int, std: float, scale: float = 10.0, x_offset: float = 0.0\n",
    "    ) -> \"GaussianMixture\":\n",
    "        angles = torch.linspace(0, 2 * np.pi, nmodes + 1)[:nmodes]\n",
    "        means = torch.stack([torch.cos(angles), torch.sin(angles)], dim=1) * scale \\\n",
    "                + torch.Tensor([1.0, 0.0]) * x_offset\n",
    "        covs = torch.diag_embed(torch.ones(nmodes, 2) * std ** 2)\n",
    "        weights = torch.ones(nmodes) / nmodes\n",
    "        return cls(means, covs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2c416-072f-48eb-acf0-6ae71416e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist2d_samples(samples, ax: Optional[Axes]=None, bins: int = 200, scale: float = 5.0, \n",
    "                   percentile: int = 99, **kwargs):\n",
    "    H, xedges, yedges = np.histogram2d(samples[:, 0], samples[:, 1], bins=bins, \\\n",
    "                                        range=[[-scale, scale], [-scale, scale]])\n",
    "    cmax = np.percentile(H, percentile)\n",
    "    cmin = 0.0\n",
    "    norm = cm.colors.Normalize(vmax=cmax, vmin=cmin)\n",
    "\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    ax.imshow(H.T, extent=extent, origin='lower', norm=norm, **kwargs)\n",
    "\n",
    "def hist2d_sampleable(sampleable: Sampleable, num_samples: int, ax: Optional[Axes] = None, bins=200, \\\n",
    "                      scale: float = 5.0, percentile: int = 99, **kwargs):\n",
    "    assert sampleable.dim == 2\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    samples = sampleable.sample(num_samples).detach().cpu()\n",
    "    hist2d_samples(samples, ax, bins, scale, percentile, **kwargs)\n",
    "\n",
    "def scatter_sampleable(sampleable: Sampleable, num_samples: int, ax: Optional[Axes] = None, **kwargs):\n",
    "    assert sampleable.dim == 2\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    samples = sampleable.sample(num_samples)\n",
    "    ax.scatter(samples[:,0].cpu(), samples[:,1].cpu(), **kwargs)\n",
    "\n",
    "def kdeplot_sampleable(sampleable: Sampleable, num_samples: int, ax: Optional[Axes] = None, **kwargs):\n",
    "    assert sampleable.dim == 2\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    samples = sampleable.sample(num_samples)\n",
    "    sns.kdeplot(x = samples[:,0].cpu(), y = samples[:,1].cpu(), ax=ax, **kwargs)\n",
    "\n",
    "def imshow_density(density: Density, x_bounds: Tuple[float, float], y_bounds: Tuple[float, float], \n",
    "                   bins: int, ax: Optional[Axes] = None, x_offset: float = 0.0, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x_min, x_max = x_bounds\n",
    "    y_min, y_max = y_bounds\n",
    "    x = torch.linspace(x_min, x_max, bins).to(device) + x_offset\n",
    "    y = torch.linspace(y_min, y_max, bins).to(device)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack([X.reshape(-1), Y.reshape(-1)], dim=-1)\n",
    "    density = density.log_density(xy).reshape(bins, bins).T\n",
    "    im = ax.imshow(density.cpu(), extent=[x_min, x_max, y_min, y_max], origin='lower', **kwargs)\n",
    "\n",
    "def contour_density(density: Density, bins: int, scale: float, ax: Optional[Axes] = None, \\\n",
    "        x_offset: float = 0.0, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = torch.linspace(-scale + x_offset, scale + x_offset, bins).to(device)\n",
    "    y = torch.linspace(-scale, scale, bins).to(device)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack([X.reshape(-1), Y.reshape(-1)], dim=-1)\n",
    "    density = density.log_density(xy).reshape(bins, bins).T\n",
    "    im = ax.contour(density.cpu(), origin='lower', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d95d5-fc2d-4d5c-b23d-3fabae363678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE(ABC):\n",
    "    @abstractmethod\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "class SDE(ABC):\n",
    "    @abstractmethod\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def diffusion_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15de82-5a9f-4a5a-b4a7-afced577a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(ABC):\n",
    "    @abstractmethod\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, dt: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate(self, x: torch.Tensor, ts: torch.Tensor):\n",
    "        for t_idx in range(len(ts) - 1):\n",
    "            t = ts[:, t_idx]\n",
    "            h = ts[:, t_idx + 1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate_with_trajectory(self, x: torch.Tensor, ts: torch.Tensor):\n",
    "        xs = [x.clone()]\n",
    "        nts = ts.shape[1]\n",
    "        for t_idx in tqdm(range(nts - 1)):\n",
    "            t = ts[:, t_idx]\n",
    "            h = ts[:, t_idx+1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h)\n",
    "            xs.append(x.clone())\n",
    "        return torch.stack(xs, dim=1)\n",
    "\n",
    "class EulerSimulator(Simulator):\n",
    "    def __init__(self, ode: ODE):\n",
    "        self.ode = ode\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor):\n",
    "        return xt + self.ode.drift_coefficient(xt, t) * h\n",
    "\n",
    "class EulerMaruyamaSimulator(Simulator):\n",
    "    def __init__(self, sde: SDE):\n",
    "        self.sde = sde\n",
    "\n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor):\n",
    "        return xt + self.sde.drift_coefficient(xt, t) * h \\\n",
    "                  + self.sde.diffusion_coefficient(xt, t) * torch.sqrt(h) * torch.randn_like(xt)\n",
    "\n",
    "def record_every(num_timesteps: int, record_every: int) -> torch.Tensor:\n",
    "    if record_every == 1:\n",
    "        return torch.arange(num_timesteps)\n",
    "    return torch.cat(\n",
    "        [\n",
    "            torch.arange(0, num_timesteps - 1, record_every),\n",
    "            torch.tensor([num_timesteps - 1]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31da28-6bfd-4aa2-a417-f0a1cc05376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalProbabilityPath(torch.nn.Module, ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for conditional probability paths\n",
    "    \"\"\"\n",
    "    def __init__(self, p_simple: Sampleable, p_data: Sampleable):\n",
    "        super().__init__()\n",
    "        self.p_simple = p_simple\n",
    "        self.p_data = p_data\n",
    "\n",
    "    def sample_marginal_path(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sample from the marginal distribution p_t(x) = p_t(x|z) p(z)\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        num_samples = t.shape[0]\n",
    "        # sample conditioning variable z \\sim p(z)\n",
    "        z = self.sample_conditioning_variable(num_samples)\n",
    "        x = self.sample_conditional_path(z, t)\n",
    "        return x\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: tim (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "            Evaluates the conditional vector field u_t(x|z)\n",
    "            Args:\n",
    "                - x: position variable (num_samples, dim)\n",
    "                - z: conditioning variable (num_samples, dim)\n",
    "                - t: time (num_samples, 1)\n",
    "            Returns:\n",
    "                - conditional_vector_field: conditional vector field (num_samples, dim)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z)\n",
    "        Args:\n",
    "            - x: position variable (num_samples, dim)\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - conditional_score: conditional_score (num_samples, dim)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7d0bf-14b5-498d-908f-b9f8cc11b4bc",
   "metadata": {},
   "source": [
    "## Part 2: Gaussian Conditional Probability Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5c702-6705-45b6-ac0d-6c565c8922f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"scale\": 15.0,\n",
    "    \"target_scale\": 10.0,\n",
    "    \"target_std\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3b39c-dad2-4403-89bd-482781d5d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_simple = Gaussian.isotropic(dim=2, std=1.0).to(device)\n",
    "p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(24,8))\n",
    "bins = 200\n",
    "\n",
    "scale = PARAMS[\"scale\"]\n",
    "x_bounds = [-scale,scale]\n",
    "y_bounds = [-scale, scale]\n",
    "\n",
    "axes[0].set_title('Heatmap of p_simple')\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=axes[0], vmin=-10,alpha=0.25,\n",
    "               cmap=plt.get_cmap('Reds'))\n",
    "\n",
    "axes[1].set_title('Heatmap of p_data')\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=axes[1], vmin=-10,alpha=0.25,\n",
    "               cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "axes[2].set_title('Heatmap of p_simple and p_data')\n",
    "axes[2].set_xticks([])\n",
    "axes[2].set_yticks([])\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7b08c-63cf-44a2-801d-7a39174d8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alpha(ABC):\n",
    "    def __init__(self):\n",
    "        assert torch.allclose(\n",
    "            self(torch.zeros(1,1)), torch.zeros(1,1)\n",
    "        )\n",
    "        assert torch.allclose(\n",
    "            self(torch.ones(1,1)), torch.ones(1,1))\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates alpha_t. Should statisfy: self(0.0) = 0.0, self(1.0) = 1.0\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - alpha_t (num_samples, 1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples, 1)\n",
    "        \"\"\"\n",
    "        t = t.unsqueeze(1)\n",
    "        dt = vmap(jacrev(self))(t)\n",
    "        return dt.view(-1, 1)\n",
    "\n",
    "class Beta(ABC):\n",
    "    def __init__(self):\n",
    "        # Check beta_0 = 1\n",
    "        assert torch.allclose( self(torch.zeros(1,1)), torch.ones(1,1))\n",
    "        # check beta_1 = 0\n",
    "        assert torch.allclose( self(torch.ones(1, 1)), torch.zeros(1,1))\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates beta_t. Should satisfy: self(0.0) = 1.0, self(1.0) = 0.0\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        t = t.unsqueeze(1)\n",
    "        dt = vmap(jacrev(self))(t)\n",
    "        return dt.view(-1, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a5193-f01f-40a4-82ab-2debc52fcdbb",
   "metadata": {},
   "source": [
    "$$\\alpha_t = t \\text{ and } \\beta_t = \\sqrt{1 - t}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70630db-7ea9-460c-a7b7-c96dfa7ca776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAlpha(Alpha):\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return t\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.ones_like(t)\n",
    "\n",
    "class SquareRootBeta(Beta):\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sqrt(1 - t)\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return - 0.5/ (torch.sqrt(1 - t) + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb849b-1a7b-4710-8aa5-15c78a93ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianConditionalProbabilityPath(ConditionalProbabilityPath):\n",
    "    def __init__(self, p_data: Sampleable, alpha: Alpha, beta: Beta):\n",
    "        p_simple = Gaussian.isotropic(p_data.dim, 1.0)\n",
    "        super().__init__(p_simple, p_data)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z ~ p_data(x)\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.p_data.sample(num_samples)\n",
    "\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - t: time (num_samples, 1(\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return self.alpha(t) * z + self.beta(t) * torch.randn_like(z)\n",
    "\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional vector field u_t(x|z)\n",
    "        \"\"\"\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        dt_alpha_t = self.alpha.dt(t)\n",
    "        dt_beta_t = self.beta.dt(t)\n",
    "\n",
    "        return (dt_alpha_t - dt_beta_t / beta_t * alpha_t) * z + dt_beta_t / beta_t * x\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates the conditional score of p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        \"\"\"\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        return (z * alpha_t - x)/beta_t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd7793-d289-4aae-8998-d710c4a12310",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device),\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = SquareRootBeta()\n",
    ").to(device)\n",
    "\n",
    "scale = PARAMS[\"scale\"]\n",
    "x_bounds = [-scale, scale]\n",
    "y_bounds = [-scale, scale]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlim(*x_bounds)\n",
    "plt.ylim(*y_bounds)\n",
    "plt.title('Gaussian Conditional Probability Path')\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "# sample conditioning variable z\n",
    "z = path.sample_conditioning_variable(1)\n",
    "ts = torch.linspace(0.0, 1.0, 7).to(device)\n",
    "\n",
    "# plot z\n",
    "plt.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=75, label='z')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "num_samples = 1000\n",
    "for t in ts:\n",
    "    zz = z.expand(num_samples, 2)\n",
    "    tt = t.unsqueeze(0).expand(num_samples, 1)\n",
    "    samples = path.sample_conditional_path(zz, tt)\n",
    "    plt.scatter(samples[:,0].cpu(), samples[:,1].cpu(), alpha=0.25, s = 8, label=f't={t.item():.1f}')\n",
    "\n",
    "plt.legend(prop={'size':18}, markerscale=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40571e9a-1f5f-4083-8cf1-fe7cb22d4c97",
   "metadata": {},
   "source": [
    "### Problem 2.3: Conditional vector field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267eb891-4930-4d5a-8045-72a88bc9b9a5",
   "metadata": {},
   "source": [
    "the conditional vector field $$u_t(x|z)$$ is given by\n",
    "$$u_t(x|z) = (\\dot{\\alpha_t} - \\dot{\\beta_t}/\\beta_t * \\alpha_t)z + \\dot{\\beta_t}\\beta_t * x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662eb7b2-bc35-4fc6-b80a-5981091325bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalVectorFieldODE(ODE):\n",
    "    def __init__(self, path: ConditionalProbabilityPath, z: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.path =path\n",
    "        self.z = z\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        bs = x.shape[0]\n",
    "        z = self.z.expand(bs, *self.z.shape[1:])\n",
    "        return self.path.conditional_vector_field(x, z, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69fb80-3e69-47ca-973b-2c523414d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "num_timesteps = 1000\n",
    "num_marginals = 3\n",
    "\n",
    "# setup path and plot\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device), \n",
    "    alpha = LinearAlpha(),\n",
    "    beta = SquareRootBeta(),\n",
    ").to(device)\n",
    "\n",
    "# setup figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(36,12))\n",
    "scale = PARAMS[\"scale\"]\n",
    "legend_size = 24\n",
    "markerscale = 1.8\n",
    "x_bounds = [-scale, scale]\n",
    "y_bounds = [-scale, scale]\n",
    "\n",
    "# sample conditioning variable z\n",
    "torch.cuda.manual_seed(1)\n",
    "z = path.sample_conditioning_variable(1)\n",
    "\n",
    "# graph samples\n",
    "ax = axes[1]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "#ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Samples from Conditional ODE', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "# construct integrator and plot trajectories\n",
    "ode = ConditionalVectorFieldODE(path, z)\n",
    "simulator = EulerSimulator(ode)\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "ts = torch.linspace(0.0, 1.0, num_timesteps).view(1, -1, 1).expand(num_samples, -1, 1).to(device)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts)\n",
    "\n",
    "# extract every n-th intergration step to plot\n",
    "every_n = record_every(num_timesteps=num_timesteps, record_every=num_timesteps // num_marginals)\n",
    "xts_every_n = xts[:, every_n, :]\n",
    "ts_every_n = ts[0, every_n]\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].item()\n",
    "    ax.scatter(xts_every_n[:, plot_idx, 0].detach().cpu(), xts_every_n[:, plot_idx, 1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt:.2f}')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "###\n",
    "# Graph trajectories of contional ODE\n",
    "ax = axes[2]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Trajectories of conditional ODE', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "for traj_idx in range(15):\n",
    "    ax.plot(xts[traj_idx,:,0].detach().cpu(), xts[traj_idx,:,1].detach().cpu(), alpha=0.5, color='black')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "# graph ground-truth conditional probability path\n",
    "ax = axes[0]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Ground-Truth conditional Probability path', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].unsqueeze(0).expand(num_samples,1)\n",
    "    zz = z.expand(num_samples, 2)\n",
    "    marginal_samples = path.sample_conditional_path(zz, tt)\n",
    "    ax.scatter(marginal_samples[:,0].detach().cpu(), marginal_samples[:,1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt[0,0].item():.2f}')\n",
    "# Plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42ad95-719a-4e49-bd4f-86006b248d26",
   "metadata": {},
   "source": [
    "## Problem 2.4: The Conditional Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285cd5b-6bfd-4085-95ec-b0d50f7c85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalVectorFieldSDE(SDE):\n",
    "    def __init__(self, path: ConditionalProbabilityPath, z: torch.Tensor, sigma: float):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.z = z\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        bs = x.shape[0]\n",
    "        z = self.z.expand(bs, *self.z.shape[1:])\n",
    "        return self.path.conditional_vector_field(x,z,t) + 0.5*self.sigma**2 * self.path.conditional_score(x,z,t)\n",
    "\n",
    "    def diffusion_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigma * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cabe5-089c-424c-9dde-79811788dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values\n",
    "num_samples = 500\n",
    "num_timesteps = 1000\n",
    "num_marginals = 3\n",
    "sigma = 2.5\n",
    "\n",
    "# setup path and plot\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device), \n",
    "    alpha = LinearAlpha(),\n",
    "    beta = SquareRootBeta(),\n",
    ").to(device)\n",
    "\n",
    "# setup figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(36,12))\n",
    "scale = PARAMS[\"scale\"]\n",
    "legend_size = 24\n",
    "markerscale = 1.8\n",
    "x_bounds = [-scale, scale]\n",
    "y_bounds = [-scale, scale]\n",
    "\n",
    "# sample conditioning variable z\n",
    "torch.cuda.manual_seed(1)\n",
    "z = path.sample_conditioning_variable(1)\n",
    "\n",
    "# graph samples\n",
    "ax = axes[1]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Samples from Conditional SDE', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "# construct integrator and plot trajectories\n",
    "sde = ConditionalVectorFieldSDE(path, z, sigma)\n",
    "simulator = EulerMaruyamaSimulator(sde)\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "ts = torch.linspace(0.0, 1.0, num_timesteps).view(1, -1, 1).expand(num_samples, -1, 1).to(device)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts)\n",
    "\n",
    "# extract every n-th intergration step to plot\n",
    "every_n = record_every(num_timesteps=num_timesteps, record_every=num_timesteps // num_marginals)\n",
    "xts_every_n = xts[:, every_n, :]\n",
    "ts_every_n = ts[0, every_n]\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].item()\n",
    "    ax.scatter(xts_every_n[:, plot_idx, 0].detach().cpu(), xts_every_n[:, plot_idx, 1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt:.2f}')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "###\n",
    "# Graph trajectories of contional ODE\n",
    "ax = axes[2]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Trajectories of conditional SDE', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "for traj_idx in range(15):\n",
    "    ax.plot(xts[traj_idx,:,0].detach().cpu(), xts[traj_idx,:,1].detach().cpu(), alpha=0.5, color='black')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "# graph ground-truth conditional probability path\n",
    "ax = axes[0]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Ground-Truth conditional Probability path', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].unsqueeze(0).expand(num_samples,1)\n",
    "    zz = z.expand(num_samples, 2)\n",
    "    marginal_samples = path.sample_conditional_path(zz, tt)\n",
    "    ax.scatter(marginal_samples[:,0].detach().cpu(), marginal_samples[:,1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt[0,0].item():.2f}')\n",
    "# Plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbbbb44-1be0-43f4-a0b5-a7d087826732",
   "metadata": {},
   "source": [
    "# Part 3: Flow Matching and Score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cff5d5-2725-4b05-808f-3c70ddf2358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(dims: List[int], activation: Type[torch.nn.Module] = torch.nn.SiLU):\n",
    "    mlp = []\n",
    "    for idx in range(len(dims) - 1):\n",
    "        mlp.append(torch.nn.Linear(dims[idx], dims[idx+1]))\n",
    "        if idx < len(dims) - 2:\n",
    "            mlp.append(activation())\n",
    "    return torch.nn.Sequential(*mlp)\n",
    "\n",
    "class MLPVectorField(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    MLP0parameterization of the learned vector field u_t^\\theta(x)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, hiddens: List[int]):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.net = build_mlp([dim+1] + hiddens + [dim])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        xt = torch.cat([x,t], dim=-1)\n",
    "        return self.net(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24613fc1-686b-4968-b02e-b14cea7745e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(ABC):\n",
    "    def __init__(self, model: torch.nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_train_loss(self, **kwargs) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    def get_optimizer(self, lr: float):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def train(self, num_epochs: int, device: torch.device, lr: float=1e-3, **kwargs) -> torch.Tensor:\n",
    "        self.model.to(device)\n",
    "        opt = self.get_optimizer(lr)\n",
    "        self.model.train()\n",
    "\n",
    "        pbar = tqdm(enumerate(range(num_epochs)))\n",
    "        for idx, epoch in pbar:\n",
    "            opt.zero_grad()\n",
    "            loss = self.get_train_loss(**kwargs)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            pbar.set_description(f'Epock {idx}, loss: {loss.item()}')\n",
    "\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0111d-6853-4f15-866c-c7757c8288d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalFlowMatchingTrainer(Trainer):\n",
    "    def __init__(self, path: ConditionalProbabilityPath, model: MLPVectorField, **kwargs):\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.path = path\n",
    "\n",
    "    def get_train_loss(self, batch_size: int) -> torch.Tensor:\n",
    "        z = self.path.p_data.sample(batch_size)\n",
    "        t = torch.rand(batch_size, 1).to(z)\n",
    "        x = self.path.sample_conditional_path(z, t)\n",
    "\n",
    "        ut_theta = self.model(x, t)\n",
    "        ut_ref = self.path.conditional_vector_field(x, z, t)\n",
    "        error = torch.sum(torch.square(ut_theta - ut_ref), dim=-1)\n",
    "        return torch.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb6ce6-c554-4958-af97-41ec939025bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device), \n",
    "    alpha = LinearAlpha(),\n",
    "    beta = SquareRootBeta()\n",
    ").to(device)\n",
    "\n",
    "flow_model = MLPVectorField(dim=2, hiddens=[64,64,64,64])\n",
    "\n",
    "trainer = ConditionalFlowMatchingTrainer(path, flow_model)\n",
    "losses = trainer.train(num_epochs=5000, device=device, lr=1e-3, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d590f11-3272-4582-8d66-d756e2a461c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedVectorFieldODE(ODE):\n",
    "    def __init__(self, net: MLPVectorField):\n",
    "        self.net = net\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d946f2c-079c-4f4a-a81a-8c4aad75fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "num_timesteps = 1000\n",
    "num_marginals = 3\n",
    "\n",
    "# setup figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(36,12))\n",
    "scale = PARAMS[\"scale\"]\n",
    "legend_size = 24\n",
    "markerscale = 1.8\n",
    "x_bounds = [-scale, scale]\n",
    "y_bounds = [-scale, scale]\n",
    "\n",
    "# Graph sample from learned Marginal ODE\n",
    "ax = axes[1]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Samples from Learned Marginal ODE', fontsize=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "# construct integrator and plot trajectories\n",
    "ode = LearnedVectorFieldODE(flow_model)\n",
    "simulator = EulerSimulator(ode)\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "ts = torch.linspace(0.0, 1.0, num_timesteps).view(1, -1, 1).expand(num_samples, -1, 1).to(device)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts)\n",
    "\n",
    "# extract every n-th intergration step to plot\n",
    "every_n = record_every(num_timesteps=num_timesteps, record_every=num_timesteps // num_marginals)\n",
    "xts_every_n = xts[:, every_n, :]\n",
    "ts_every_n = ts[0, every_n]\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].item()\n",
    "    ax.scatter(xts_every_n[:, plot_idx, 0].detach().cpu(), xts_every_n[:, plot_idx, 1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt:.2f}')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "###\n",
    "# Graph trajectories of contional ODE\n",
    "ax = axes[2]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Trajectories of conditional ODE', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "for traj_idx in range(15):\n",
    "    ax.plot(xts[traj_idx,:,0].detach().cpu(), xts[traj_idx,:,1].detach().cpu(), alpha=0.5, color='black')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "# graph ground-truth conditional probability path\n",
    "ax = axes[0]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Ground-Truth conditional Probability path', fontsize=20)\n",
    "ax.scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].unsqueeze(0).expand(num_samples,1)\n",
    "    zz = z.expand(num_samples, 2)\n",
    "    marginal_samples = path.sample_conditional_path(zz, tt)\n",
    "    ax.scatter(marginal_samples[:,0].detach().cpu(), marginal_samples[:,1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt[0,0].item():.2f}')\n",
    "# Plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f85e4-cbdf-450f-a228-8aaaf6d2fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPScore(torch.nn.Module):\n",
    "    def __init__(self, dim: int, hiddens: List[int]):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.net = build_mlp([dim+1] + hiddens + [dim])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        xt = torch.cat([x, t], dim=-1)\n",
    "        return self.net(xt)\n",
    "\n",
    "class ConditionalScoreMatchingTrainer(Trainer):\n",
    "    def __init__(self, path: ConditionalProbabilityPath, model: MLPScore, **kwargs):\n",
    "        super().__init__(model, **kwargs)\n",
    "        self.path = path\n",
    "\n",
    "    def get_train_loss(self, batch_size: int) -> torch.Tensor:\n",
    "        z = self.path.p_data.sample(batch_size)\n",
    "        t = torch.rand(batch_size, 1).to(z)\n",
    "        x = self.path.sample_conditional_path(z,t)\n",
    "\n",
    "        s_theta = self.model(x,t)\n",
    "        s_ref = self.path.conditional_score(x, z, t)\n",
    "        mse = torch.sum(torch.square(s_theta - s_ref), dim=-1)\n",
    "        return torch.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc01eca-db7b-4880-a17a-e4787b1e6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device), \n",
    "    alpha = LinearAlpha(),\n",
    "    beta = SquareRootBeta()\n",
    ").to(device)\n",
    "\n",
    "score_model = MLPScore(dim=2, hiddens=[64,64,64,64])\n",
    "\n",
    "trainer = ConditionalScoreMatchingTrainer(path, score_model)\n",
    "losses = trainer.train(num_epochs=1000, device=device, lr=1e-3, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ee273-0591-422a-9548-c65daa7ba579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangevinFlowSDE(SDE):\n",
    "    def __init__(self, flow_model: MLPVectorField, score_model: MLPScore, sigma: float):\n",
    "        super().__init__()\n",
    "        self.flow_model = flow_model\n",
    "        self.score_model = score_model\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.flow_model(x,t) + 0.5*self.sigma**2 * self.score_model(x,t)\n",
    "\n",
    "    def diffusion_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigma * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89f578-c7f0-4610-8c7b-84c86e6a7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values\n",
    "num_samples = 1000\n",
    "num_timesteps = 300\n",
    "num_marginals = 3\n",
    "sigma = 2.0\n",
    "\n",
    "\n",
    "scale = PARAMS[\"scale\"]\n",
    "x_bounds = [-scale, scale]\n",
    "y_bounds = [-scale, scale]\n",
    "legend_size = 24\n",
    "markerscale = 1.8\n",
    "\n",
    "# setup figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(36,12))\n",
    "\n",
    "# sample conditioning variable z\n",
    "torch.cuda.manual_seed(1)\n",
    "z = path.sample_conditioning_variable(1)\n",
    "\n",
    "# graph samples\n",
    "ax = axes[1]\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Samples from Learned Marginal SDE', fontsize=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "# construct integrator and plot trajectories\n",
    "sde = LangevinFlowSDE(flow_model, score_model, sigma)\n",
    "simulator = EulerMaruyamaSimulator(sde)\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "ts = torch.linspace(0.0, 1.0, num_timesteps).view(1, -1, 1).expand(num_samples, -1, 1).to(device)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts)\n",
    "\n",
    "# extract every n-th intergration step to plot\n",
    "every_n = record_every(num_timesteps=num_timesteps, record_every=num_timesteps // num_marginals)\n",
    "xts_every_n = xts[:, every_n, :]\n",
    "ts_every_n = ts[0, every_n]\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].item()\n",
    "    ax.scatter(xts_every_n[:, plot_idx, 0].detach().cpu(), xts_every_n[:, plot_idx, 1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt:.2f}')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "###\n",
    "# Graph trajectories of contional ODE\n",
    "ax = axes[2]\n",
    "\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Trajectories of learned marginal SDE', fontsize=20)\n",
    "\n",
    "# plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "for traj_idx in range(15):\n",
    "    ax.plot(xts[traj_idx,:,0].detach().cpu(), xts[traj_idx,:,1].detach().cpu(), alpha=0.5, color='black')\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "# graph ground-truth conditional probability path\n",
    "ax = axes[0]\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_title('Ground-Truth Marginal Probability path', fontsize=20)\n",
    "\n",
    "\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].unsqueeze(0).expand(num_samples,1)\n",
    "    marginal_samples = path.sample_marginal_path(tt)\n",
    "    ax.scatter(marginal_samples[:,0].detach().cpu(), marginal_samples[:,1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt[0,0].item():.2f}')\n",
    "# Plot source and target\n",
    "imshow_density(density=p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993faf5-1440-40e2-b32d-94beda6f7ed0",
   "metadata": {},
   "source": [
    "## Question 3.3: Deriving the Marginal Score from the Marginal Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96dfcfc-c280-41dc-8fa9-1d3fb577bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreFromVectorField(torch.nn.Module):\n",
    "    def __init__(self, vector_field: MLPVectorField, alpha: Alpha, beta: Beta):\n",
    "        super().__init__()\n",
    "        self.vector_field = vector_field\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "\n",
    "        dt_alpha_t = self.alpha.dt(t)\n",
    "        dt_beta_t = self.beta.dt(t)\n",
    "\n",
    "        num = alpha_t * self.vector_field(x,t) - dt_alpha_t * x\n",
    "        den = beta_t**2 * dt_alpha_t - alpha_t * dt_beta_t * beta_t\n",
    "\n",
    "        return num/ den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c840f-c5d4-4c47-a5d3-ee942e24df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 30\n",
    "num_marginals = 4\n",
    "\n",
    "# construct probability path\n",
    "path = GaussianConditionalProbabilityPath(\n",
    "    p_data = GaussianMixture.symmetric_2D(nmodes=5, std=PARAMS[\"target_std\"], scale=PARAMS[\"target_scale\"]).to(device), \n",
    "    alpha = LinearAlpha(),\n",
    "    beta = SquareRootBeta(),\n",
    ").to(device)\n",
    "\n",
    "# define score networks\n",
    "learned_score_model = score_model\n",
    "flow_score_model = ScoreFromVectorField(flow_model, path.alpha, path.beta)\n",
    "\n",
    "# plot score fields over time\n",
    "fig, axes = plt.subplots(2, num_marginals, figsize=(6*num_marginals, 12))\n",
    "axes = axes.reshape((2, num_marginals))\n",
    "\n",
    "scale = PARAMS['scale']\n",
    "ts = torch.linspace(0.0, 0.9999, num_marginals).to(device)\n",
    "xs = torch.linspace(-scale, scale, num_bins).to(device)\n",
    "ys = torch.linspace(-scale, scale, num_bins).to(device)\n",
    "xx, yy = torch.meshgrid(xs, ys)\n",
    "xx = xx.reshape(-1, 1)\n",
    "yy = yy.reshape(-1, 1)\n",
    "xy = torch.cat([xx,yy], dim=-1)\n",
    "\n",
    "axes[0,0].set_ylabel('Learned with score mathing', fontsize=12)\n",
    "axes[1,0].set_ylabel('computed from $u_t^{{\\\\theta}}(x)$', fontsize=12)\n",
    "\n",
    "for idx in range(num_marginals):\n",
    "    t = ts[idx]\n",
    "    bs = num_bins ** 2\n",
    "    tt = t.view(1,1).expand(bs, 1)\n",
    "\n",
    "    learned_scores = learned_score_model(xy, tt)\n",
    "    learned_scores_x = learned_scores[:,0]\n",
    "    learned_scores_y = learned_scores[:,1]\n",
    "\n",
    "    ax = axes[0, idx]\n",
    "    ax.quiver(xx.detach().cpu(), yy.detach().cpu(), learned_scores_x.detach().cpu(), learned_scores_y.detach().cpu(), scale=125, alpha=0.5)\n",
    "    imshow_density(density=path.p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "    imshow_density(density=path.p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "    ax.set_title(f'$s_{{t}}^{{\\\\theta}}$ at t={t.item():.2f}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # flow score model\n",
    "    ax = axes\n",
    "    flow_scores = flow_score_model(xy, tt)\n",
    "    flow_scores_x = flow_scores[:,0]\n",
    "    flow_scores_y = flow_scores[:,1]\n",
    "\n",
    "    ax = axes[1, idx]\n",
    "    ax.quiver(xx.detach().cpu(), yy.detach().cpu(), flow_scores_x.detach().cpu(), flow_scores_y.detach().cpu(), scale=125, alpha=0.5)\n",
    "    imshow_density(density=path.p_simple, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Reds'))\n",
    "    imshow_density(density=path.p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "    ax.set_title(f'$\\\\tilde{{s}}_{{t}}^{{\\\\theta}}$ at t={t.item():.2f}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c2d02-4d5c-4850-b51a-bed0acaecb4c",
   "metadata": {},
   "source": [
    "# Part 4: Flow Matching Between Arbitrary Dist with a Lieanr Prob Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32eeba-5771-494f-acf0-e218256caab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonsSampleable(Sampleable):\n",
    "    def __init__(self, device: torch.device, noise: float = 0.05, scale: float = 5.0, offset: Optional[torch.Tensor] = None):\n",
    "        self.noise = noise\n",
    "        self.scale = scale\n",
    "        self.device = device\n",
    "        if offset is None:\n",
    "            offset = torch.zeros(2)\n",
    "        self.offset = offset.to(device)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return 2\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        samples, _ = make_moons(\n",
    "            n_samples=num_samples,\n",
    "            noise=self.noise,\n",
    "            random_state=None\n",
    "        )\n",
    "        return self.scale * torch.from_numpy(samples.astype(np.float32)).to(self.device) + self.offset\n",
    "\n",
    "class CirclesSampleable(Sampleable):\n",
    "    def __init__(self, device: torch.device, noise: float=0.05, scale=5.0, offset:Optional[torch.Tensor]=None):\n",
    "        self.noise = noise\n",
    "        self.scale = scale\n",
    "        self.device = device\n",
    "        if offset is None:\n",
    "            offset = torch.zeros(2)\n",
    "        self.offset = offset.to(device)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return 2\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        samples, _ = make_circles(\n",
    "            n_samples=num_samples,\n",
    "            noise=self.noise,\n",
    "            factor=0.5,\n",
    "            random_state=None\n",
    "        )\n",
    "        return self.scale * torch.from_numpy(samples.astype(np.float32)).to(self.device) + self.offset\n",
    "\n",
    "class CheckerboardSampleable(Sampleable):\n",
    "    def __init__(self, device: torch.device, grid_size: int = 3, scale=5.0):\n",
    "        self.grid_size = grid_size\n",
    "        self.scale = scale\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return 2\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        grid_length = 2 * self.scale / self.grid_size\n",
    "        samples = torch.zeros(0,2).to(device)\n",
    "        while samples.shape[0] < num_samples:\n",
    "            new_samples = (torch.rand(num_samples,2).to(self.device) - 0.5)*2*self.scale\n",
    "            x_mask = torch.floor((new_samples[:,0] + self.scale)/grid_length)%2 == 0\n",
    "            y_mask = torch.floor((new_samples[:,1] + self.scale)/grid_length) % 2 == 0\n",
    "            accept_mask = torch.logical_xor(~x_mask, y_mask)\n",
    "            samples = torch.cat([samples, new_samples[accept_mask]], dim=0)\n",
    "        return samples[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4f8cd-ba4b-4ce3-a45a-1b6c227f7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize alternative choices of p_data\n",
    "targets = {\n",
    "    \"circles\": CirclesSampleable(device),\n",
    "    \"moons\": MoonsSampleable(device, scale=3.5),\n",
    "    \"checkerboard\": CheckerboardSampleable(device, grid_size=4)\n",
    "}\n",
    "\n",
    "###################################\n",
    "# Graph Various Choices of p_data #\n",
    "###################################\n",
    "\n",
    "fig, axes = plt.subplots(1, len(targets), figsize=(6 * len(targets), 6))\n",
    "\n",
    "num_samples=20000\n",
    "num_bins = 100\n",
    "for idx, (target_name, target) in enumerate(targets.items()):\n",
    "    ax = axes[idx]\n",
    "    hist2d_sampleable(target, num_samples, bins=bins, scale=7.5, ax=ax)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Histogram of {target_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c165a-f11a-46a1-a7a5-d789283437a7",
   "metadata": {},
   "source": [
    "## Problem 4.1: Linear Probability Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de874e9a-f91b-49df-a0a0-0437b32bc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearConditionalProbabilityPath(ConditionalProbabilityPath):\n",
    "    def __init__(self, p_simple: Sampleable, p_data: Sampleable):\n",
    "        super().__init__(p_simple, p_data)\n",
    "\n",
    "    def sample_conditioning_variable(self, num_samples: int) -> torch.Tensor:\n",
    "        return self.p_data.sample(num_samples)\n",
    "\n",
    "    def sample_conditional_path(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        x0 = self.p_simple.sample(z.shape[0])\n",
    "        return (1 - t)*x0 + t*z\n",
    "\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        return (z - x)/(1 - t)\n",
    "        \n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        raise Exception(\"you should not be calling this function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666d1db-9947-4192-9d00-87af4a168404",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "num_timesteps = 500\n",
    "num_marginals = 5\n",
    "assert num_timesteps % (num_marginals - 1) == 0\n",
    "\n",
    "path = LinearConditionalProbabilityPath(\n",
    "    p_simple = CirclesSampleable(device), #Gaussian.isotropic(dim=2, std=1.0),\n",
    "    p_data = CheckerboardSampleable(device, grid_size=4)\n",
    ").to(device)\n",
    "\n",
    "z = path.p_data.sample(1)\n",
    "\n",
    "fig, axes = plt.subplots(3, num_marginals, figsize=(6*num_marginals, 6*3))\n",
    "axes = axes.reshape(3, num_marginals)\n",
    "scale = 6.0\n",
    "\n",
    "ts = torch.linspace(0.0, 1.0, num_marginals).to(device)\n",
    "for idx, t in enumerate(ts):\n",
    "    zz = z.expand(num_samples, -1)\n",
    "    tt = t.view(1,1).expand(num_samples, 1)\n",
    "    xts = path.sample_conditional_path(zz, tt)\n",
    "    percentile = min(99 + 2 * torch.sin(t).item(), 100)\n",
    "    hist2d_samples(samples=xts.cpu(), ax=axes[0,idx], bins=300, scale=scale, percentile=percentile, alpha=1.0)\n",
    "    axes[0,idx].set_xlim(-scale,scale)\n",
    "    axes[0,idx].set_ylim(-scale,scale)\n",
    "    axes[0,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[0,0].set_ylabel('conditional (from ground-truth)', fontsize=20)\n",
    "\n",
    "# plot z\n",
    "axes[0,-1].scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "axes[0,-1].legend()\n",
    "\n",
    "# Graph conditional prob paths using conditional_vector_field\n",
    "ode = ConditionalVectorFieldODE(path, z)\n",
    "simulator = EulerSimulator(ode)\n",
    "ts = torch.linspace(0,1, num_timesteps).to(device)\n",
    "record_every_idxs = record_every(len(ts), len(ts) // (num_marginals -1))\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts.view(1,-1,1).expand(num_samples,-1,1))\n",
    "xts = xts[:,record_every_idxs,:]\n",
    "for idx in range(xts.shape[1]):\n",
    "    xx = xts[:,idx,:]\n",
    "    tt = ts[record_every_idxs[idx]]\n",
    "    percentile = min(99 + 2*torch.sin(tt).item(), 100)\n",
    "    hist2d_samples(samples=xx.cpu(), ax=axes[1,idx], bins=300, scale=scale, percentile=percentile, alpha=1.0)\n",
    "    axes[1,idx].set_xlim(-scale,scale)\n",
    "    axes[1,idx].set_ylim(-scale,scale)\n",
    "    axes[1,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[1,0].set_ylabel('conditional (from ODE)', fontsize=20)   \n",
    "\n",
    "# plot z\n",
    "axes[1,-1].scatter(z[:,0].cpu(), z[:,1].cpu(), marker='*', color='red', s=200, label='z', zorder=20)\n",
    "axes[1,-1].legend()\n",
    "\n",
    "# graph conditional prob path using sample_marginal_path\n",
    "ts = torch.linspace(0.0, 1.0, num_marginals).to(device)\n",
    "for idx, t in enumerate(ts):\n",
    "    zz = z.expand(num_samples, -1)\n",
    "    tt = t.view(1,1).expand(num_samples, 1)\n",
    "    xts = path.sample_marginal_path(tt)\n",
    "    hist2d_samples(samples=xts.cpu(), ax=axes[2,idx], bins=300, scale=scale, percentile=99, alpha=1.0)\n",
    "    axes[0,idx].set_xlim(-scale,scale)\n",
    "    axes[0,idx].set_ylim(-scale,scale)\n",
    "    axes[0,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[0,0].set_ylabel('marginal', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183645f4-1472-425f-83be-4e4e43e40977",
   "metadata": {},
   "source": [
    "## part 4.2: Flow matching with linear prob paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918f937-2445-465a-b7e8-dcf60b14ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = LinearConditionalProbabilityPath(\n",
    "    p_simple = Gaussian.isotropic(dim=2, std=1.0),\n",
    "    p_data = CheckerboardSampleable(device, grid_size=4)\n",
    ").to(device)\n",
    "\n",
    "linear_flow_model = MLPVectorField(dim=2, hiddens=[64,64,64,64])\n",
    "\n",
    "trainer = ConditionalFlowMatchingTrainer(path, linear_flow_model)\n",
    "losses = trainer.train(num_epochs=10000, device=device, lr=1e-3, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a32d8-9c74-47f2-92e2-667daa58a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 50000\n",
    "num_marginals = 5\n",
    "\n",
    "fig, axes = plt.subplots(2, num_marginals, figsize=(6*num_marginals, 6*3))\n",
    "axes = axes.reshape(2, num_marginals)\n",
    "scale = 6.0\n",
    "\n",
    "ts = torch.linspace(0.0, 1.0, num_marginals).to(device)\n",
    "for idx, t in enumerate(ts):\n",
    "    tt = t.view(1,1).expand(num_samples, 1)\n",
    "    xts = path.sample_marginal_path(tt)\n",
    "    hist2d_samples(samples=xts.cpu(), ax=axes[0,idx], bins=300, scale=scale, percentile=99, alpha=1.0)\n",
    "    axes[0,idx].set_xlim(-scale,scale)\n",
    "    axes[0,idx].set_ylim(-scale,scale)\n",
    "    axes[0,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[0,0].set_ylabel('ground-truth', fontsize=20)\n",
    "\n",
    "# Graph conditional prob paths using conditional_vector_field\n",
    "ode = LearnedVectorFieldODE(linear_flow_model) #ConditionalVectorFieldODE(path, z)\n",
    "simulator = EulerSimulator(ode)\n",
    "ts = torch.linspace(0,1, num_timesteps).to(device)\n",
    "record_every_idxs = record_every(len(ts), len(ts) // (num_marginals -1))\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts.view(1,-1,1).expand(num_samples,-1,1))\n",
    "xts = xts[:,record_every_idxs,:]\n",
    "for idx in range(xts.shape[1]):\n",
    "    xx = xts[:,idx,:]\n",
    "    tt = ts[record_every_idxs[idx]]\n",
    "    percentile = min(99 + 2*torch.sin(tt).item(), 100)\n",
    "    hist2d_samples(samples=xx.cpu(), ax=axes[1,idx], bins=300, scale=scale, percentile=percentile, alpha=1.0)\n",
    "    axes[1,idx].set_xlim(-scale,scale)\n",
    "    axes[1,idx].set_ylim(-scale,scale)\n",
    "    axes[1,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[1,0].set_ylabel('conditional (from ODE)', fontsize=20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c77d0-2ff2-4e98-9a06-ddd93ede93cb",
   "metadata": {},
   "source": [
    "## Problem 4.3: Bridging Between arbitrary source and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53e870-3f86-446a-9d40-19b3ac382ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = LinearConditionalProbabilityPath(\n",
    "    p_simple = CirclesSampleable(device),\n",
    "    p_data = CheckerboardSampleable(device, grid_size=4)\n",
    ").to(device)\n",
    "\n",
    "bridging_flow_model = MLPVectorField(dim=2, hiddens=[100,100,100,100])\n",
    "\n",
    "trainer = ConditionalFlowMatchingTrainer(path, bridging_flow_model)\n",
    "losses = trainer.train(num_epochs=20000, device=device, lr=1e-3, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d824b2-ad60-467d-9e45-8c53df053161",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 30000\n",
    "num_marginals = 5\n",
    "\n",
    "fig, axes = plt.subplots(2, num_marginals, figsize=(6 * num_marginals, 6 * 2))\n",
    "axes = axes.reshape(2, num_marginals)\n",
    "scale = 6.0\n",
    "\n",
    "ts = torch.linspace(0.0, 1.0, num_marginals).to(device)\n",
    "for idx, t in enumerate(ts):\n",
    "    tt = t.view(1,1).expand(num_samples,1)\n",
    "    xts = path.sample_marginal_path(tt)\n",
    "    hist2d_samples(samples=xts.cpu(), ax=axes[0,idx], bins=200, scale=scale, percentile=99, alpha=1.0)\n",
    "    axes[0, idx].set_xlim(-scale,scale)\n",
    "    axes[0,idx].set_ylim(-scale,scale)\n",
    "    axes[0,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[0,0].set_ylabel('ground truth', fontsize=15)\n",
    "\n",
    "ode = LearnedVectorFieldODE(bridging_flow_model)\n",
    "simulator = EulerSimulator(ode)\n",
    "ts = torch.linspace(0,1,200).to(device)\n",
    "record_every_idxs = record_every(len(ts), len(ts)//(num_marginals-1))\n",
    "x0 = path.p_simple.sample(num_samples)\n",
    "xts = simulator.simulate_with_trajectory(x0, ts.view(1,-1,1).expand(num_samples,-1,1))\n",
    "xts = xts[:,record_every_idxs,:]\n",
    "for idx in range(xts.shape[1]):\n",
    "    xx = xts[:,idx,:]\n",
    "    hist2d_samples(samples=xx.cpu(), ax=axes[1,idx], bins=200, scale=scale, percentile=99, alpha=1.0)\n",
    "    axes[1, idx].set_xlim(-scale,scale)\n",
    "    axes[1,idx].set_ylim(-scale,scale)\n",
    "    axes[1,idx].set_title(f'$t={t.item():.2f}$', fontsize=15)\n",
    "axes[1,0].set_ylabel('learned', fontsize=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4dbf5c-2aa2-437d-bbbb-1b830d6746d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "sd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
